### ğŸ§ª Senaryo 1: Bir dosya yÃ¼kleme sistemi kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k dosyalar yÃ¼klemesine imkan tanÄ±yor. Sistem yÃ¼klenen dosyalarÄ± geÃ§ici olarak sunucu diskinde saklar. KullanÄ±cÄ±lar farklÄ± boyutlarda dosyalar yÃ¼kleyebilir. YÃ¼kleme iÅŸlemi sÄ±rasÄ±nda disk alanÄ± kullanÄ±lÄ±r.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 38
```csharp

using Microsoft.AspNetCore.Http;
using Microsoft.AspNetCore.Mvc;
using System.IO;
using System.Threading.Tasks;

[ApiController]
[Route("[controller]")]
public class FileUploadController : ControllerBase
{
    private readonly string _tempUploadPath = Path.Combine(Path.GetTempPath(), "Uploads");

    public FileUploadController()
    {
        if (!Directory.Exists(_tempUploadPath))
        {
            Directory.CreateDirectory(_tempUploadPath);
        }
    }

    [HttpPost("upload")]
    public async Task<IActionResult> UploadFile(IFormFile file)
    {
        if (file == null || file.Length == 0)
        {
            return BadRequest("No file uploaded.");
        }

        var filePath = Path.Combine(_tempUploadPath, file.FileName);

        using (var stream = new FileStream(filePath, FileMode.Create))
        {
            await file.CopyToAsync(stream);
        }

        return Ok(new { Message = "File uploaded successfully", FileName = file.FileName, Size = file.Length });
    }
}
```
### ğŸ§ª Senaryo 1: Bir dosya yÃ¼kleme sistemi kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k dosyalar yÃ¼klemesine imkan tanÄ±yor. Sistem yÃ¼klenen dosyalarÄ± geÃ§ici olarak sunucu diskinde saklar. KullanÄ±cÄ±lar farklÄ± boyutlarda dosyalar yÃ¼kleyebilir. YÃ¼kleme iÅŸlemi sÄ±rasÄ±nda disk alanÄ± kullanÄ±lÄ±r.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 29
```python

from flask import Flask, request, jsonify
import os

app = Flask(__name__)
UPLOAD_FOLDER = 'temp_uploads'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({'error': 'No file part in the request'}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No selected file'}), 400
    if file:
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
        file.save(filepath)
        return jsonify({
            'message': 'File uploaded successfully',
            'filename': file.filename,
            'size': os.path.getsize(filepath)
        }), 200

if __name__ == '__main__':
    app.run(debug=True)
```
### ğŸ§ª Senaryo 1: Bir dosya yÃ¼kleme sistemi kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k dosyalar yÃ¼klemesine imkan tanÄ±yor. Sistem yÃ¼klenen dosyalarÄ± geÃ§ici olarak sunucu diskinde saklar. KullanÄ±cÄ±lar farklÄ± boyutlarda dosyalar yÃ¼kleyebilir. YÃ¼kleme iÅŸlemi sÄ±rasÄ±nda disk alanÄ± kullanÄ±lÄ±r.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 39
```typescript

import express from 'express';
import multer from 'multer';
import path from 'path';
import fs from 'fs';

const app = express();
const port = 3000;

const tempUploadPath = path.join(__dirname, 'temp_uploads');
if (!fs.existsSync(tempUploadPath)) {
    fs.mkdirSync(tempUploadPath);
}

const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        cb(null, tempUploadPath);
    },
    filename: (req, file, cb) => {
        cb(null, file.originalname);
    }
});

const upload = multer({ storage: storage });

app.post('/upload', upload.single('file'), (req, res) => {
    if (!req.file) {
        return res.status(400).send('No file uploaded.');
    }
    res.status(200).json({
        message: 'File uploaded successfully',
        fileName: req.file.originalname,
        size: req.file.size
    });
});

app.listen(port, () => {
    console.log(`Server running on http://localhost:${port}`);
});
```
### ğŸ§ª Senaryo 2: Bir API servisi dakikada Ã§ok sayÄ±da istek alabiliyor. KullanÄ±cÄ±lar bu servise sÃ¼rekli Ã§aÄŸrÄ± yapabilir. Sistem gelen istekleri iÅŸleyerek yanÄ±t dÃ¶ndÃ¼rÃ¼r. Her istek sunucu kaynaklarÄ±nÄ± kullanÄ±r.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 21
```csharp

using Microsoft.AspNetCore.Mvc;
using System.Threading.Tasks;

[ApiController]
[Route("[controller]")]
public class ApiServiceController : ControllerBase
{
    private static int _requestCount = 0;

    [HttpGet("process-request")]
    public async Task<IActionResult> ProcessRequest()
    {
        // Simulate some processing work
        await Task.Delay(50); // Simulate 50ms of work
        Interlocked.Increment(ref _requestCount); // Increment request counter

        // Log or store request details (for simplicity, just returning a message)
        return Ok(new { Message = "Request processed successfully", RequestId = Guid.NewGuid(), CurrentRequestCount = _requestCount });
    }
}
```
### ğŸ§ª Senaryo 2: Bir API servisi dakikada Ã§ok sayÄ±da istek alabiliyor. KullanÄ±cÄ±lar bu servise sÃ¼rekli Ã§aÄŸrÄ± yapabilir. Sistem gelen istekleri iÅŸleyerek yanÄ±t dÃ¶ndÃ¼rÃ¼r. Her istek sunucu kaynaklarÄ±nÄ± kullanÄ±r.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 26
```python

from flask import Flask, jsonify
import time
import threading

app = Flask(__name__)
request_count = 0
request_count_lock = threading.Lock()

@app.route('/process-request', methods=['GET'])
def process_request():
    global request_count
    # Simulate some processing work
    time.sleep(0.05) # Simulate 50ms of work

    with request_count_lock:
        request_count += 1

    return jsonify({
        'message': 'Request processed successfully',
        'request_id': str(threading.get_ident()),
        'current_request_count': request_count
    }), 200

if __name__ == '__main__':
    app.run(debug=True)
```
### ğŸ§ª Senaryo 2: Bir API servisi dakikada Ã§ok sayÄ±da istek alabiliyor. KullanÄ±cÄ±lar bu servise sÃ¼rekli Ã§aÄŸrÄ± yapabilir. Sistem gelen istekleri iÅŸleyerek yanÄ±t dÃ¶ndÃ¼rÃ¼r. Her istek sunucu kaynaklarÄ±nÄ± kullanÄ±r.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 23
```typescript

import express from 'express';

const app = express();
const port = 3000;

let requestCount = 0;

app.get('/process-request', async (req, res) => {
    // Simulate some processing work
    await new Promise(resolve => setTimeout(resolve, 50)); // Simulate 50ms of work
    requestCount++;

    res.status(200).json({
        message: 'Request processed successfully',
        requestId: Math.random().toString(36).substring(2, 15),
        currentRequestCount: requestCount
    });
});

app.listen(port, () => {
    console.log(`API Service running on http://localhost:${port}`);
});
```
### ğŸ§ª Senaryo 3: Bir log sistemi sÃ¼rekli olarak gelen verileri dosyalara yazÄ±yor. Uygulama Ã§alÄ±ÅŸÄ±rken farklÄ± modÃ¼llerden log mesajlarÄ± gelir. Bu mesajlar dosyalara sÄ±ralÄ± ÅŸekilde kaydedilir. Sistem Ã§alÄ±ÅŸtÄ±ÄŸÄ± sÃ¼re boyunca log dosyalarÄ± bÃ¼yÃ¼r.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 48
```csharp

using System;
using System.IO;
using System.Threading.Tasks;

public class LogSystem
{
    private readonly string _logFilePath;
    private static readonly object _lock = new object();

    public LogSystem(string logFileName = "application.log")
    {
        _logFilePath = Path.Combine(AppDomain.CurrentDomain.BaseDirectory, logFileName);
    }

    public async Task WriteLogAsync(string module, string message)
    {
        var logEntry = $"{DateTime.UtcNow:yyyy-MM-dd HH:mm:ss} [{module}] {message}{Environment.NewLine}";

        // Use a lock to ensure sequential writes to the file
        lock (_lock)
        {
            File.AppendAllText(_logFilePath, logEntry);
        }
        // For asynchronous, consider a producer-consumer pattern with a background writer
        // This simple lock example works for basic scenarios.
    }
}

// Example usage in an application:
/*
public class MyService
{
    private readonly LogSystem _logger = new LogSystem();

    public async Task DoSomething()
    {
        await _logger.WriteLogAsync("ModuleA", "Operation started.");
        // ... some work ...
        await _logger.WriteLogAsync("ModuleA", "Operation completed successfully.");
    }

    public async Task AnotherAction()
    {
        await _logger.WriteLogAsync("ModuleB", "Processing data.");
    }
}
*/
```
### ğŸ§ª Senaryo 3: Bir log sistemi sÃ¼rekli olarak gelen verileri dosyalara yazÄ±yor. Uygulama Ã§alÄ±ÅŸÄ±rken farklÄ± modÃ¼llerden log mesajlarÄ± gelir. Bu mesajlar dosyalara sÄ±ralÄ± ÅŸekilde kaydedilir. Sistem Ã§alÄ±ÅŸtÄ±ÄŸÄ± sÃ¼re boyunca log dosyalarÄ± bÃ¼yÃ¼r.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 20
```python

import logging
import os
from datetime import datetime

class LogSystem:
    def __init__(self, log_file_name="application.log"):
        self.log_file_path = os.path.join(os.getcwd(), log_file_name)
        logging.basicConfig(filename=self.log_file_path, level=logging.INFO,
                            format='%(asctime)s [%(name)s] %(message)s',
                            datefmt='%Y-%m-%d %H:%M:%S')
        self.logger = logging.getLogger('ApplicationLogger')

    def write_log(self, module, message):
        self.logger.info(f"[{module}] {message}")

# Example usage:
# log_system = LogSystem()
# log_system.write_log("ModuleA", "User logged in.")
# log_system.write_log("ModuleB", "Database query executed.")
```
### ğŸ§ª Senaryo 3: Bir log sistemi sÃ¼rekli olarak gelen verileri dosyalara yazÄ±yor. Uygulama Ã§alÄ±ÅŸÄ±rken farklÄ± modÃ¼llerden log mesajlarÄ± gelir. Bu mesajlar dosyalara sÄ±ralÄ± ÅŸekilde kaydedilir. Sistem Ã§alÄ±ÅŸtÄ±ÄŸÄ± sÃ¼re boyunca log dosyalarÄ± bÃ¼yÃ¼r.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 29
```typescript

import winston from 'winston';
import path from 'path';

const logFilePath = path.join(__dirname, 'application.log');

const logger = winston.createLogger({
    level: 'info',
    format: winston.format.combine(
        winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
        winston.format.printf(({ timestamp, level, message, module }) => {
            return `${timestamp} [${module || 'App'}] ${message}`;
        })
    ),
    transports: [
        new winston.transports.File({ filename: logFilePath })
    ]
});

export class LogSystem {
    public writeLog(module: string, message: string): void {
        logger.info(message, { module });
    }
}

// Example usage:
// const logSystem = new LogSystem();
// logSystem.writeLog("ModuleA", "Data processing started.");
// logSystem.writeLog("ModuleC", "Configuration loaded.");
```
### ğŸ§ª Senaryo 4: Bir web uygulamasÄ±nda kullanÄ±cÄ±lar karmaÅŸÄ±k arama sorgularÄ± yapabiliyor. Arama iÅŸlemi veritabanÄ±nda birden fazla tablo Ã¼zerinde Ã§alÄ±ÅŸÄ±r. DetaylÄ± arama kriterleri Ã§ok sayÄ±da kayÄ±t kontrolÃ¼ gerektirir. Arama sonuÃ§larÄ± kullanÄ±cÄ±ya liste halinde sunulur.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 84
```csharp

using Microsoft.AspNetCore.Mvc;
using Microsoft.EntityFrameworkCore;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;

// Assuming you have an Entity Framework Core DbContext set up
public class ApplicationDbContext : DbContext
{
    public DbSet<Product> Products { get; set; }
    public DbSet<Category> Categories { get; set; }
    public DbSet<Supplier> Suppliers { get; set; }

    public ApplicationDbContext(DbContextOptions<ApplicationDbContext> options) : base(options) { }
}

public class Product
{
    public int Id { get; set; }
    public string Name { get; set; }
    public string Description { get; set; }
    public decimal Price { get; set; }
    public int CategoryId { get; set; }
    public Category Category { get; set; }
    public int SupplierId { get; set; }
    public Supplier Supplier { get; set; }
}

public class Category { public int Id { get; set; } public string Name { get; set; } }
public class Supplier { public int Id { get; set; } public string Name { get; set; } }

public class SearchCriteria
{
    public string Keyword { get; set; }
    public decimal? MinPrice { get; set; }
    public decimal? MaxPrice { get; set; }
    public string CategoryName { get; set; }
    public string SupplierName { get; set; }
}

[ApiController]
[Route("[controller]")]
public class SearchController : ControllerBase
{
    private readonly ApplicationDbContext _context;

    public SearchController(ApplicationDbContext context)
    {
        _context = context;
    }

    [HttpGet("search")]
    public async Task<IActionResult> Search([FromQuery] SearchCriteria criteria)
    {
        IQueryable<Product> query = _context.Products
            .Include(p => p.Category)
            .Include(p => p.Supplier);

        if (!string.IsNullOrEmpty(criteria.Keyword))
        {
            query = query.Where(p => p.Name.Contains(criteria.Keyword) || p.Description.Contains(criteria.Keyword));
        }
        if (criteria.MinPrice.HasValue)
        {
            query = query.Where(p => p.Price >= criteria.MinPrice.Value);
        }
        if (criteria.MaxPrice.HasValue)
        {
            query = query.Where(p => p.Price <= criteria.MaxPrice.Value);
        }
        if (!string.IsNullOrEmpty(criteria.CategoryName))
        {
            query = query.Where(p => p.Category.Name.Contains(criteria.CategoryName));
        }
        if (!string.IsNullOrEmpty(criteria.SupplierName))
        {
            query = query.Where(p => p.Supplier.Name.Contains(criteria.SupplierName));
        }

        var results = await query.ToListAsync();
        return Ok(results);
    }
}
```
### ğŸ§ª Senaryo 4: Bir web uygulamasÄ±nda kullanÄ±cÄ±lar karmaÅŸÄ±k arama sorgularÄ± yapabiliyor. Arama iÅŸlemi veritabanÄ±nda birden fazla tablo Ã¼zerinde Ã§alÄ±ÅŸÄ±r. DetaylÄ± arama kriterleri Ã§ok sayÄ±da kayÄ±t kontrolÃ¼ gerektirir. Arama sonuÃ§larÄ± kullanÄ±cÄ±ya liste halinde sunulur.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 69
```python

from flask import Flask, request, jsonify
from flask_sqlalchemy import SQLAlchemy

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///search_example.db'
db = SQLAlchemy(app)

class Product(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(80), nullable=False)
    description = db.Column(db.String(200))
    price = db.Column(db.Float)
    category_id = db.Column(db.Integer, db.ForeignKey('category.id'))
    category = db.relationship('Category', backref=db.backref('products', lazy=True))
    supplier_id = db.Column(db.Integer, db.ForeignKey('supplier.id'))
    supplier = db.relationship('Supplier', backref=db.backref('products', lazy=True))

class Category(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(80), nullable=False)

class Supplier(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(80), nullable=False)

# Create database tables (run once)
with app.app_context():
    db.create_all()

@app.route('/search', methods=['GET'])
def search_products():
    keyword = request.args.get('keyword')
    min_price = request.args.get('min_price', type=float)
    max_price = request.args.get('max_price', type=float)
    category_name = request.args.get('category_name')
    supplier_name = request.args.get('supplier_name')

    query = Product.query.join(Category).join(Supplier)

    if keyword:
        query = query.filter(
            (Product.name.like(f'%{keyword}%')) |
            (Product.description.like(f'%{keyword}%'))
        )
    if min_price is not None:
        query = query.filter(Product.price >= min_price)
    if max_price is not None:
        query = query.filter(Product.price <= max_price)
    if category_name:
        query = query.filter(Category.name.like(f'%{category_name}%'))
    if supplier_name:
        query = query.filter(Supplier.name.like(f'%{supplier_name}%'))

    results = []
    for product in query.all():
        results.append({
            'id': product.id,
            'name': product.name,
            'description': product.description,
            'price': product.price,
            'category': product.category.name if product.category else None,
            'supplier': product.supplier.name if product.supplier else None
        })

    return jsonify(results)

if __name__ == '__main__':
    app.run(debug=True)
```
### ğŸ§ª Senaryo 4: Bir web uygulamasÄ±nda kullanÄ±cÄ±lar karmaÅŸÄ±k arama sorgularÄ± yapabiliyor. Arama iÅŸlemi veritabanÄ±nda birden fazla tablo Ã¼zerinde Ã§alÄ±ÅŸÄ±r. DetaylÄ± arama kriterleri Ã§ok sayÄ±da kayÄ±t kontrolÃ¼ gerektirir. Arama sonuÃ§larÄ± kullanÄ±cÄ±ya liste halinde sunulur.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 105
```typescript

import express from 'express';
import { DataSource, Entity, PrimaryGeneratedColumn, Column, ManyToOne, JoinColumn } from 'typeorm';

// Assuming TypeORM setup
@Entity()
export class Product {
    @PrimaryGeneratedColumn()
    id!: number;

    @Column()
    name!: string;

    @Column({ nullable: true })
    description?: string;

    @Column('decimal')
    price!: number;

    @ManyToOne(() => Category)
    @JoinColumn({ name: 'categoryId' })
    category!: Category;

    @Column()
    categoryId!: number;

    @ManyToOne(() => Supplier)
    @JoinColumn({ name: 'supplierId' })
    supplier!: Supplier;

    @Column()
    supplierId!: number;
}

@Entity()
export class Category {
    @PrimaryGeneratedColumn()
    id!: number;

    @Column()
    name!: string;
}

@Entity()
export class Supplier {
    @PrimaryGeneratedColumn()
    id!: number;

    @Column()
    name!: string;
}

const AppDataSource = new DataSource({
    type: 'sqlite',
    database: 'search_example.db',
    synchronize: true,
    entities: [Product, Category, Supplier],
});

AppDataSource.initialize()
    .then(() => {
        console.log('Data Source has been initialized!');
    })
    .catch((err) => {
        console.error('Error during Data Source initialization:', err);
    });

const app = express();
const port = 3000;

app.get('/search', async (req, res) => {
    const { keyword, minPrice, maxPrice, categoryName, supplierName } = req.query;

    const productRepository = AppDataSource.getRepository(Product);

    let queryBuilder = productRepository.createQueryBuilder('product')
        .leftJoinAndSelect('product.category', 'category')
        .leftJoinAndSelect('product.supplier', 'supplier');

    if (keyword) {
        queryBuilder = queryBuilder.andWhere(
            '(product.name LIKE :keyword OR product.description LIKE :keyword)',
            { keyword: `%${keyword}%` }
        );
    }
    if (minPrice) {
        queryBuilder = queryBuilder.andWhere('product.price >= :minPrice', { minPrice: parseFloat(minPrice as string) });
    }
    if (maxPrice) {
        queryBuilder = queryBuilder.andWhere('product.price <= :maxPrice', { maxPrice: parseFloat(maxPrice as string) });
    }
    if (categoryName) {
        queryBuilder = queryBuilder.andWhere('category.name LIKE :categoryName', { categoryName: `%${categoryName}%` });
    }
    if (supplierName) {
        queryBuilder = queryBuilder.andWhere('supplier.name LIKE :supplierName', { supplierName: `%${supplierName}%` });
    }

    const results = await queryBuilder.getMany();
    res.status(200).json(results);
});

app.listen(port, () => {
    console.log(`Search service running on http://localhost:${port}`);
});
```
### ğŸ§ª Senaryo 5: Bir video iÅŸleme uygulamasÄ± kullanÄ±cÄ±larÄ±n yÃ¼klediÄŸi videolarÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yor. FarklÄ± formatlardaki videolar sisteme yÃ¼klenebilir. DÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemi sÄ±rasÄ±nda Ã§eÅŸitli kodekler kullanÄ±lÄ±r. Ä°ÅŸlenmiÅŸ videolar kullanÄ±cÄ±lara sunulur.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 73
```csharp

using System;
using System.IO;
using System.Threading.Tasks;
using Microsoft.AspNetCore.Http;
using Microsoft.AspNetCore.Mvc;

// Simulate a video processing library (e.g., FFmpeg wrapper)
public class VideoProcessor
{
    public async Task<bool> ConvertVideoAsync(string inputFilePath, string outputFilePath, string targetFormat)
    {
        Console.WriteLine($"Starting conversion of {inputFilePath} to {targetFormat} at {outputFilePath}...");
        // In a real application, you would invoke an external tool like FFmpeg here
        // Example: Process.Start("ffmpeg", $"-i {inputFilePath} -o {outputFilePath} -f {targetFormat}");
        await Task.Delay(TimeSpan.FromSeconds(5)); // Simulate conversion time
        Console.WriteLine("Video conversion completed.");
        File.WriteAllText(outputFilePath, "This is a simulated converted video file content."); // Create dummy output
        return true;
    }
}

[ApiController]
[Route("[controller]")]
public class VideoProcessingController : ControllerBase
{
    private readonly string _uploadPath = Path.Combine(Path.GetTempPath(), "VideoUploads");
    private readonly string _outputPath = Path.Combine(Path.GetTempPath(), "ProcessedVideos");
    private readonly VideoProcessor _videoProcessor = new VideoProcessor();

    public VideoProcessingController()
    {
        if (!Directory.Exists(_uploadPath)) Directory.CreateDirectory(_uploadPath);
        if (!Directory.Exists(_outputPath)) Directory.CreateDirectory(_outputPath);
    }

    [HttpPost("upload-and-convert")]
    public async Task<IActionResult> UploadAndConvert(IFormFile file, [FromQuery] string targetFormat = "mp4")
    {
        if (file == null || file.Length == 0) return BadRequest("No file uploaded.");

        var inputFilePath = Path.Combine(_uploadPath, file.FileName);
        using (var stream = new FileStream(inputFilePath, FileMode.Create))
        {
            await file.CopyToAsync(stream);
        }

        var outputFileName = $"{Path.GetFileNameWithoutExtension(file.FileName)}.{targetFormat}";
        var outputFilePath = Path.Combine(_outputPath, outputFileName);

        bool success = await _videoProcessor.ConvertVideoAsync(inputFilePath, outputFilePath, targetFormat);

        if (success)
        {
            // In a real scenario, you might return a URL to the processed video
            return Ok(new { Message = "Video converted successfully", ProcessedFile = outputFileName, DownloadUrl = $"/videos/{outputFileName}" });
        }
        return StatusCode(500, "Video conversion failed.");
    }

    // Example endpoint to serve processed videos (basic for demonstration)
    [HttpGet("videos/{fileName}")]
    public IActionResult GetProcessedVideo(string fileName)
    {
        var filePath = Path.Combine(_outputPath, fileName);
        if (!System.IO.File.Exists(filePath))
        {
            return NotFound();
        }
        var fileBytes = System.IO.File.ReadAllBytes(filePath);
        return File(fileBytes, "application/octet-stream", fileName); // Or appropriate video MIME type
    }
}
```
### ğŸ§ª Senaryo 5: Bir video iÅŸleme uygulamasÄ± kullanÄ±cÄ±larÄ±n yÃ¼klediÄŸi videolarÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yor. FarklÄ± formatlardaki videolar sisteme yÃ¼klenebilir. DÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemi sÄ±rasÄ±nda Ã§eÅŸitli kodekler kullanÄ±lÄ±r. Ä°ÅŸlenmiÅŸ videolar kullanÄ±cÄ±lara sunulur.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 64
```python

from flask import Flask, request, jsonify, send_from_directory
import os
import time

app = Flask(__name__)
UPLOAD_FOLDER = 'video_uploads'
PROCESSED_FOLDER = 'processed_videos'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['PROCESSED_FOLDER'] = PROCESSED_FOLDER

if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)
if not os.path.exists(PROCESSED_FOLDER):
    os.makedirs(PROCESSED_FOLDER)

class VideoProcessor:
    def convert_video(self, input_filepath, output_filepath, target_format):
        print(f"Starting conversion of {input_filepath} to {target_format} at {output_filepath}...")
        # Simulate video conversion using a dummy file creation
        # In a real app, you'd use a library like moviepy or call an external tool like FFmpeg
        time.sleep(5)  # Simulate conversion time
        with open(output_filepath, 'w') as f:
            f.write("This is a simulated converted video file content.")
        print("Video conversion completed.")
        return True

video_processor = VideoProcessor()

@app.route('/upload-and-convert', methods=['POST'])
def upload_and_convert():
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No selected file'}), 400

    target_format = request.args.get('target_format', 'mp4')

    if file:
        input_filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
        file.save(input_filepath)

        filename_without_ext = os.path.splitext(file.filename)[0]
        output_filename = f"{filename_without_ext}.{target_format}"
        output_filepath = os.path.join(app.config['PROCESSED_FOLDER'], output_filename)

        success = video_processor.convert_video(input_filepath, output_filepath, target_format)

        if success:
            return jsonify({
                'message': 'Video converted successfully',
                'processed_file': output_filename,
                'download_url': f'/videos/{output_filename}'
            }), 200
        else:
            return jsonify({'error': 'Video conversion failed'}), 500

@app.route('/videos/<filename>', methods=['GET'])
def get_processed_video(filename):
    return send_from_directory(app.config['PROCESSED_FOLDER'], filename)

if __name__ == '__main__':
    app.run(debug=True)
```
### ğŸ§ª Senaryo 5: Bir video iÅŸleme uygulamasÄ± kullanÄ±cÄ±larÄ±n yÃ¼klediÄŸi videolarÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yor. FarklÄ± formatlardaki videolar sisteme yÃ¼klenebilir. DÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemi sÄ±rasÄ±nda Ã§eÅŸitli kodekler kullanÄ±lÄ±r. Ä°ÅŸlenmiÅŸ videolar kullanÄ±cÄ±lara sunulur.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 94
```typescript

import express from 'express';
import multer from 'multer';
import path from 'path';
import fs from 'fs';
import util from 'util';
import { exec as execCallback } from 'child_process';

const exec = util.promisify(execCallback);

const app = express();
const port = 3000;

const uploadPath = path.join(__dirname, 'video_uploads');
const processedPath = path.join(__dirname, 'processed_videos');

if (!fs.existsSync(uploadPath)) {
    fs.mkdirSync(uploadPath);
}
if (!fs.existsSync(processedPath)) {
    fs.mkdirSync(processedPath);
}

const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        cb(null, uploadPath);
    },
    filename: (req, file, cb) => {
        cb(null, file.originalname);
    }
});

const upload = multer({ storage: storage });

class VideoProcessor {
    public async convertVideo(inputFilePath: string, outputFilePath: string, targetFormat: string): Promise<boolean> {
        console.log(`Starting conversion of ${inputFilePath} to ${targetFormat} at ${outputFilePath}...`);
        // In a real application, you'd use a tool like ffmpeg.
        // Example using ffmpeg (requires ffmpeg to be installed on the system):
        // const command = `ffmpeg -i "${inputFilePath}" "${outputFilePath}"`;
        // try {
        //     await exec(command);
        //     console.log('FFmpeg conversion successful.');
        //     return true;
        // } catch (error) {
        //     console.error('FFmpeg conversion failed:', error);
        //     return false;
        // }

        // Simulate conversion by creating a dummy file
        await new Promise(resolve => setTimeout(resolve, 5000)); // Simulate 5 seconds processing
        fs.writeFileSync(outputFilePath, 'This is a simulated converted video file content.');
        console.log('Simulated video conversion completed.');
        return true;
    }
}

const videoProcessor = new VideoProcessor();

app.post('/upload-and-convert', upload.single('file'), async (req, res) => {
    if (!req.file) {
        return res.status(400).send('No file uploaded.');
    }

    const inputFilePath = req.file.path;
    const targetFormat = (req.query.targetFormat as string) || 'mp4';
    const outputFileName = `${path.parse(req.file.originalname).name}.${targetFormat}`;
    const outputFilePath = path.join(processedPath, outputFileName);

    const success = await videoProcessor.convertVideo(inputFilePath, outputFilePath, targetFormat);

    if (success) {
        return res.status(200).json({
            message: 'Video converted successfully',
            processedFile: outputFileName,
            downloadUrl: `/videos/${outputFileName}`
        });
    } else {
        return res.status(500).send('Video conversion failed.');
    }
});

app.get('/videos/:filename', (req, res) => {
    const filePath = path.join(processedPath, req.params.filename);
    if (fs.existsSync(filePath)) {
        res.sendFile(filePath);
    } else {
        res.status(404).send('File not found.');
    }
});

app.listen(port, () => {
    console.log(`Video processing app listening on http://localhost:${port}`);
});
```
### ğŸ§ª Senaryo 6: Bir sosyal medya platformu kullanÄ±cÄ±larÄ±n fotoÄŸraflarÄ±nÄ± yÃ¼klemelerine olanak tanÄ±yor. YÃ¼klenen fotoÄŸraflar farklÄ± boyutlarda olabilir. Sistem bu fotoÄŸraflarÄ± thumbnail oluÅŸturmak iÃ§in iÅŸler. Ä°ÅŸlenen fotoÄŸraflar kullanÄ±cÄ± profillerinde gÃ¶sterilir.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 94
```csharp

using Microsoft.AspNetCore.Http;
using Microsoft.AspNetCore.Mvc;
using System.IO;
using System.Threading.Tasks;
using SixLabors.ImageSharp;
using SixLabors.ImageSharp.Processing;

// Assuming you have a storage service to save processed images
public interface IImageStorageService
{
    Task<string> SaveImageAsync(Stream imageStream, string fileName, string folder);
}

public class LocalImageStorageService : IImageStorageService
{
    private readonly string _basePath;

    public LocalImageStorageService(string basePath)
    {
        _basePath = basePath;
        if (!Directory.Exists(_basePath)) Directory.CreateDirectory(_basePath);
    }

    public async Task<string> SaveImageAsync(Stream imageStream, string fileName, string folder)
    {
        var folderPath = Path.Combine(_basePath, folder);
        if (!Directory.Exists(folderPath)) Directory.CreateDirectory(folderPath);

        var filePath = Path.Combine(folderPath, fileName);
        using (var fileStream = new FileStream(filePath, FileMode.Create))
        {
            await imageStream.CopyToAsync(fileStream);
        }
        return Path.Combine(folder, fileName); // Return relative path or URL
    }
}

[ApiController]
[Route("[controller]")]
public class PhotoUploadController : ControllerBase
{
    private readonly IImageStorageService _storageService;

    public PhotoUploadController(IImageStorageService storageService)
    {
        _storageService = storageService;
    }

    [HttpPost("upload-photo")]
    public async Task<IActionResult> UploadPhoto(IFormFile file)
    {
        if (file == null || file.Length == 0)
        {
            return BadRequest("No photo uploaded.");
        }

        using (var memoryStream = new MemoryStream())
        {
            await file.CopyToAsync(memoryStream);
            memoryStream.Position = 0; // Reset stream position for ImageSharp

            // Save original image
            var originalFileName = $"{Guid.NewGuid()}{Path.GetExtension(file.FileName)}";
            var originalImagePath = await _storageService.SaveImageAsync(memoryStream, originalFileName, "originals");

            // Generate thumbnail
            memoryStream.Position = 0; // Reset stream position again
            using (var image = await Image.LoadAsync(memoryStream))
            {
                image.Mutate(x => x.Resize(new ResizeOptions
                {
                    Size = new Size(150, 150), // Thumbnail size
                    Mode = ResizeMode.Crop
                }));

                using (var thumbnailStream = new MemoryStream())
                {
                    await image.SaveAsJpegAsync(thumbnailStream); // Save as JPEG
                    thumbnailStream.Position = 0;
                    var thumbnailFileName = $"{Guid.NewGuid()}_thumb.jpg";
                    var thumbnailImagePath = await _storageService.SaveImageAsync(thumbnailStream, thumbnailFileName, "thumbnails");

                    return Ok(new
                    {
                        Message = "Photo uploaded and thumbnail generated successfully",
                        OriginalUrl = originalImagePath,
                        ThumbnailUrl = thumbnailImagePath
                    });
                }
            }
        }
    }
}
```
### ğŸ§ª Senaryo 6: Bir sosyal medya platformu kullanÄ±cÄ±larÄ±n fotoÄŸraflarÄ±nÄ± yÃ¼klemelerine olanak tanÄ±yor. YÃ¼klenen fotoÄŸraflar farklÄ± boyutlarda olabilir. Sistem bu fotoÄŸraflarÄ± thumbnail oluÅŸturmak iÃ§in iÅŸler. Ä°ÅŸlenen fotoÄŸraflar kullanÄ±cÄ± profillerinde gÃ¶sterilir.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 57
```python

from flask import Flask, request, jsonify, send_from_directory
from PIL import Image
import os
import uuid

app = Flask(__name__)
UPLOAD_FOLDER = 'photo_uploads/originals'
THUMBNAIL_FOLDER = 'photo_uploads/thumbnails'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['THUMBNAIL_FOLDER'] = THUMBNAIL_FOLDER

if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)
if not os.path.exists(THUMBNAIL_FOLDER):
    os.makedirs(THUMBNAIL_FOLDER)

@app.route('/upload-photo', methods=['POST'])
def upload_photo():
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No selected file'}), 400

    if file:
        file_extension = os.path.splitext(file.filename)[1]
        unique_filename = f"{uuid.uuid4()}{file_extension}"
        original_filepath = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        file.save(original_filepath)

        # Generate thumbnail
        try:
            img = Image.open(original_filepath)
            img.thumbnail((150, 150)) # Resize to 150x150, maintaining aspect ratio
            thumbnail_filename = f"{uuid.uuid4()}_thumb.jpg" # Always save thumbnails as JPEG
            thumbnail_filepath = os.path.join(app.config['THUMBNAIL_FOLDER'], thumbnail_filename)
            img.save(thumbnail_filepath, "JPEG")

            return jsonify({
                'message': 'Photo uploaded and thumbnail generated successfully',
                'original_url': f'/photos/originals/{unique_filename}',
                'thumbnail_url': f'/photos/thumbnails/{thumbnail_filename}'
            }), 200
        except Exception as e:
            return jsonify({'error': f'Image processing failed: {str(e)}'}), 500

@app.route('/photos/originals/<filename>', methods=['GET'])
def get_original_photo(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)

@app.route('/photos/thumbnails/<filename>', methods=['GET'])
def get_thumbnail_photo(filename):
    return send_from_directory(app.config['THUMBNAIL_FOLDER'], filename)

if __name__ == '__main__':
    app.run(debug=True)
```
### ğŸ§ª Senaryo 6: Bir sosyal medya platformu kullanÄ±cÄ±larÄ±n fotoÄŸraflarÄ±nÄ± yÃ¼klemelerine olanak tanÄ±yor. YÃ¼klenen fotoÄŸraflar farklÄ± boyutlarda olabilir. Sistem bu fotoÄŸraflarÄ± thumbnail oluÅŸturmak iÃ§in iÅŸler. Ä°ÅŸlenen fotoÄŸraflar kullanÄ±cÄ± profillerinde gÃ¶sterilir.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 84
```typescript

import express from 'express';
import multer from 'multer';
import path from 'path';
import fs from 'fs';
import sharp from 'sharp'; // For image processing

const app = express();
const port = 3000;

const uploadPath = path.join(__dirname, 'photo_uploads', 'originals');
const thumbnailPath = path.join(__dirname, 'photo_uploads', 'thumbnails');

if (!fs.existsSync(uploadPath)) {
    fs.mkdirSync(uploadPath, { recursive: true });
}
if (!fs.existsSync(thumbnailPath)) {
    fs.mkdirSync(thumbnailPath, { recursive: true });
}

const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        cb(null, uploadPath);
    },
    filename: (req, file, cb) => {
        cb(null, `${Date.now()}-${file.originalname}`);
    }
});

const upload = multer({ storage: storage });

app.post('/upload-photo', upload.single('file'), async (req, res) => {
    if (!req.file) {
        return res.status(400).send('No photo uploaded.');
    }

    const originalFilePath = req.file.path;
    const originalFileName = req.file.filename;

    // Generate thumbnail
    const thumbnailFileName = `${path.parse(originalFileName).name}_thumb.jpg`;
    const thumbnailFilePath = path.join(thumbnailPath, thumbnailFileName);

    try {
        await sharp(originalFilePath)
            .resize(150, 150, {
                fit: sharp.fit.cover,
                position: sharp.strategy.attention
            })
            .jpeg({ quality: 80 })
            .toFile(thumbnailFilePath);

        res.status(200).json({
            message: 'Photo uploaded and thumbnail generated successfully',
            originalUrl: `/photos/originals/${originalFileName}`,
            thumbnailUrl: `/photos/thumbnails/${thumbnailFileName}`
        });
    } catch (error) {
        console.error('Image processing failed:', error);
        res.status(500).send('Image processing failed.');
    }
});

app.get('/photos/originals/:filename', (req, res) => {
    const filePath = path.join(uploadPath, req.params.filename);
    if (fs.existsSync(filePath)) {
        res.sendFile(filePath);
    } else {
        res.status(404).send('Original photo not found.');
    }
});

app.get('/photos/thumbnails/:filename', (req, res) => {
    const filePath = path.join(thumbnailPath, req.params.filename);
    if (fs.existsSync(filePath)) {
        res.sendFile(filePath);
    } else {
        res.status(404).send('Thumbnail photo not found.');
    }
});

app.listen(port, () => {
    console.log(`Social media photo app listening on http://localhost:${port}`);
});
```
### ğŸ§ª Senaryo 7: Bir oyun sunucusu aynÄ± anda Ã§ok sayÄ±da oyuncuya hizmet verebiliyor. Her oyuncu sunucuyla aktif baÄŸlantÄ± kurar. Oyun sÄ±rasÄ±nda oyuncular arasÄ±nda sÃ¼rekli veri alÄ±ÅŸveriÅŸi yapÄ±lÄ±r. Sunucu tÃ¼m oyuncu verilerini bellekte tutar.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 168
```csharp

using System;
using System.Collections.Concurrent;
using System.Net.WebSockets;
using System.Text;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.AspNetCore.Builder;
using Microsoft.AspNetCore.Hosting;
using Microsoft.AspNetCore.Http;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Hosting;

public class Player
{
    public string Id { get; set; }
    public string Username { get; set; }
    public WebSocket WebSocket { get; set; }
    public ConcurrentDictionary<string, object> GameData { get; set; } = new ConcurrentDictionary<string, object>(); // In-memory data

    public Player(string id, WebSocket ws)
    {
        Id = id;
        WebSocket = ws;
    }
}

public class GameServer
{
    private readonly ConcurrentDictionary<string, Player> _players = new ConcurrentDictionary<string, Player>();

    public async Task AddPlayerAsync(string playerId, WebSocket webSocket)
    {
        var player = new Player(playerId, webSocket);
        _players.TryAdd(playerId, player);
        Console.WriteLine($"Player {playerId} connected. Total players: {_players.Count}");

        // Initialize some game data for the player
        player.GameData["xPos"] = 0.0f;
        player.GameData["yPos"] = 0.0f;
        player.GameData["score"] = 0;

        await SendMessageToPlayerAsync(player, "Welcome to the game!");
    }

    public void RemovePlayer(string playerId)
    {
        _players.TryRemove(playerId, out _);
        Console.WriteLine($"Player {playerId} disconnected. Total players: {_players.Count}");
    }

    public async Task HandlePlayerMessageAsync(string playerId, string message)
    {
        if (_players.TryGetValue(playerId, out var player))
        {
            Console.WriteLine($"Received from {playerId}: {message}");
            // Parse message, update player game data, and potentially broadcast
            if (message.StartsWith("MOVE "))
            {
                var parts = message.Split(' ');
                if (parts.Length == 3 && float.TryParse(parts[1], out float x) && float.TryParse(parts[2], out float y))
                {
                    player.GameData["xPos"] = x;
                    player.GameData["yPos"] = y;
                    await BroadcastMessageAsync($"{player.Username ?? player.Id} moved to ({x}, {y})");
                }
            } else if (message.StartsWith("SCORE ")) {
                var parts = message.Split(' ');
                if (parts.Length == 2 && int.TryParse(parts[1], out int score)) {
                    player.GameData["score"] = score;
                    await BroadcastMessageAsync($"{player.Username ?? player.Id} scored {score} points!");
                }
            }
            // Echo back for demonstration
            await SendMessageToPlayerAsync(player, $"Server received: {message}");
        }
    }

    public async Task SendMessageToPlayerAsync(Player player, string message)
    {
        if (player.WebSocket.State == WebSocketState.Open)
        {
            var bytes = Encoding.UTF8.GetBytes(message);
            await player.WebSocket.SendAsync(new ArraySegment<byte>(bytes, 0, bytes.Length), WebSocketMessageType.Text, true, CancellationToken.None);
        }
    }

    public async Task BroadcastMessageAsync(string message)
    {
        var bytes = Encoding.UTF8.GetBytes(message);
        foreach (var playerEntry in _players)
        {
            var player = playerEntry.Value;
            if (player.WebSocket.State == WebSocketState.Open)
            {
                try
                {
                    await player.WebSocket.SendAsync(new ArraySegment<byte>(bytes, 0, bytes.Length), WebSocketMessageType.Text, true, CancellationToken.None);
                }
                catch (WebSocketException ex)
                {
                    Console.WriteLine($"Error broadcasting to player {player.Id}: {ex.Message}");
                    // Handle disconnected player
                    RemovePlayer(player.Id);
                }
            }
        }
    }

    public ConcurrentDictionary<string, Player> GetPlayers()
    {
        return _players;
    }
}

public class Startup
{
    public void ConfigureServices(IServiceCollection services)
    {
        services.AddSingleton<GameServer>();
    }

    public void Configure(IApplicationBuilder app, IWebHostEnvironment env)
    {
        if (env.IsDevelopment())
        {
            app.UseDeveloperExceptionPage();
        }

        app.UseWebSockets();

        app.Use(async (context, next) =>
        {
            if (context.Request.Path == "/ws")
            {
                if (context.WebSockets.IsWebSocketRequest)
                {
                    WebSocket webSocket = await context.WebSockets.AcceptWebSocketAsync();
                    var gameServer = context.RequestServices.GetRequiredService<GameServer>();
                    var playerId = Guid.NewGuid().ToString("N"); // Simple ID for demonstration

                    await gameServer.AddPlayerAsync(playerId, webSocket);

                    var buffer = new byte[1024 * 4];
                    WebSocketReceiveResult result = await webSocket.ReceiveAsync(new ArraySegment<byte>(buffer), CancellationToken.None);

                    while (!result.CloseStatus.HasValue)
                    {
                        string message = Encoding.UTF8.GetString(buffer, 0, result.Count);
                        await gameServer.HandlePlayerMessageAsync(playerId, message);
                        result = await webSocket.ReceiveAsync(new ArraySegment<byte>(buffer), CancellationToken.None);
                    }

                    await webSocket.CloseAsync(result.CloseStatus.Value, result.CloseStatusDescription, CancellationToken.None);
                    gameServer.RemovePlayer(playerId);
                }
                else
                {
                    context.Response.StatusCode = StatusCodes.Status400BadRequest;
                }
            }
            else
            {
                await next();
            }
        });
    }
}
```
### ğŸ§ª Senaryo 7: Bir oyun sunucusu aynÄ± anda Ã§ok sayÄ±da oyuncuya hizmet verebiliyor. Her oyuncu sunucuyla aktif baÄŸlantÄ± kurar. Oyun sÄ±rasÄ±nda oyuncular arasÄ±nda sÃ¼rekli veri alÄ±ÅŸveriÅŸi yapÄ±lÄ±r. Sunucu tÃ¼m oyuncu verilerini bellekte tutar.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 101
```python

import asyncio
import websockets
import json
import uuid

class Player:
    def __init__(self, websocket, player_id):
        self.websocket = websocket
        self.id = player_id
        self.username = f"Player_{player_id[:4]}"
        self.game_data = { # In-memory data for the player
            "x_pos": 0.0,
            "y_pos": 0.0,
            "score": 0
        }

class GameServer:
    def __init__(self):
        self.connected_players = {} # Dictionary to store active players {player_id: Player_object}

    async def register_player(self, websocket):
        player_id = str(uuid.uuid4())
        player = Player(websocket, player_id)
        self.connected_players[player_id] = player
        print(f"Player {player.username} ({player_id}) connected. Total players: {len(self.connected_players)}")
        await self.send_message_to_player(player, f"Welcome to the game, {player.username}!")
        return player

    async def unregister_player(self, player_id):
        if player_id in self.connected_players:
            player = self.connected_players.pop(player_id)
            print(f"Player {player.username} ({player_id}) disconnected. Total players: {len(self.connected_players)}")

    async def handle_message(self, player, message):
        print(f"Received from {player.username} ({player.id}): {message}")
        try:
            data = json.loads(message)
            message_type = data.get('type')

            if message_type == 'move':
                x = data.get('x')
                y = data.get('y')
                if isinstance(x, (int, float)) and isinstance(y, (int, float)):
                    player.game_data['x_pos'] = x
                    player.game_data['y_pos'] = y
                    await self.broadcast_message(f"{player.username} moved to ({x}, {y})")
            elif message_type == 'score_update':
                score = data.get('score')
                if isinstance(score, int):
                    player.game_data['score'] = score
                    await self.broadcast_message(f"{player.username} scored {score} points! Current total: {player.game_data['score']}")
            # Add more game logic here
            else:
                await self.send_message_to_player(player, "Unknown message type.")
        except json.JSONDecodeError:
            await self.send_message_to_player(player, "Invalid JSON format.")
        except Exception as e:
            print(f"Error handling message: {e}")
            await self.send_message_to_player(player, f"Server error: {e}")

    async def send_message_to_player(self, player, message):
        try:
            await player.websocket.send(message)
        except websockets.exceptions.ConnectionClosedOK:
            print(f"Connection closed for {player.username} when sending message.")
            await self.unregister_player(player.id)
        except Exception as e:
            print(f"Error sending message to {player.username}: {e}")

    async def broadcast_message(self, message):
        if not self.connected_players:
            return
        # Create a list of send tasks to run concurrently
        send_tasks = [
            self.send_message_to_player(player, message)
            for player_id, player in self.connected_players.items()
        ]
        await asyncio.gather(*send_tasks)

game_server = GameServer()

async def websocket_handler(websocket, path):
    player = await game_server.register_player(websocket)
    try:
        async for message in websocket:
            await game_server.handle_message(player, message)
    except websockets.exceptions.ConnectionClosedOK:
        print(f"Player {player.username} disconnected normally.")
    except Exception as e:
        print(f"Error in websocket connection for {player.username}: {e}")
    finally:
        await game_server.unregister_player(player.id)

async def main():
    print("Game server starting on ws://localhost:8765")
    async with websockets.serve(websocket_handler, "localhost", 8765):
        await asyncio.Future() # Run forever

if __name__ == '__main__':
    asyncio.run(main())
```
### ğŸ§ª Senaryo 7: Bir oyun sunucusu aynÄ± anda Ã§ok sayÄ±da oyuncuya hizmet verebiliyor. Her oyuncu sunucuyla aktif baÄŸlantÄ± kurar. Oyun sÄ±rasÄ±nda oyuncular arasÄ±nda sÃ¼rekli veri alÄ±ÅŸveriÅŸi yapÄ±lÄ±r. Sunucu tÃ¼m oyuncu verilerini bellekte tutar.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 120
```typescript

import WebSocket, { WebSocketServer } from 'ws';
import http from 'http';

interface PlayerData {
    xPos: number;
    yPos: number;
    score: number;
    username: string;
}

interface Player {
    id: string;
    ws: WebSocket;
    data: PlayerData;
}

class GameServer {
    private players: Map<string, Player> = new Map();

    public addPlayer(ws: WebSocket): Player {
        const playerId = Math.random().toString(36).substring(2, 15);
        const player: Player = {
            id: playerId,
            ws: ws,
            data: {
                xPos: 0,
                yPos: 0,
                score: 0,
                username: `Player_${playerId.substring(0, 4)}`
            }
        };
        this.players.set(playerId, player);
        console.log(`Player ${player.data.username} (${playerId}) connected. Total players: ${this.players.size}`);
        this.sendMessageToPlayer(player, JSON.stringify({ type: 'welcome', message: `Welcome ${player.data.username}!` }));
        return player;
    }

    public removePlayer(playerId: string): void {
        const player = this.players.get(playerId);
        if (player) {
            this.players.delete(playerId);
            console.log(`Player ${player.data.username} (${playerId}) disconnected. Total players: ${this.players.size}`);
        }
    }

    public handleMessage(playerId: string, message: string): void {
        const player = this.players.get(playerId);
        if (!player) return;

        console.log(`Received from ${player.data.username} (${playerId}): ${message}`);

        try {
            const parsedMessage = JSON.parse(message);
            switch (parsedMessage.type) {
                case 'move':
                    player.data.xPos = parsedMessage.x;
                    player.data.yPos = parsedMessage.y;
                    this.broadcastMessage(JSON.stringify({ type: 'playerMove', playerId: player.id, x: player.data.xPos, y: player.data.yPos }));
                    break;
                case 'scoreUpdate':
                    player.data.score = parsedMessage.score;
                    this.broadcastMessage(JSON.stringify({ type: 'scoreBoard', playerId: player.id, score: player.data.score, username: player.data.username }));
                    break;
                case 'chat':
                    this.broadcastMessage(JSON.stringify({ type: 'chatMessage', sender: player.data.username, message: parsedMessage.text }));
                    break;
                default:
                    this.sendMessageToPlayer(player, JSON.stringify({ type: 'error', message: 'Unknown message type.' }));
                    break;
            }
        } catch (error) {
            console.error(`Error parsing message from ${playerId}:`, error);
            this.sendMessageToPlayer(player, JSON.stringify({ type: 'error', message: 'Invalid message format.' }));
        }
    }

    public sendMessageToPlayer(player: Player, message: string): void {
        if (player.ws.readyState === WebSocket.OPEN) {
            player.ws.send(message);
        }
    }

    public broadcastMessage(message: string): void {
        this.players.forEach(player => {
            if (player.ws.readyState === WebSocket.OPEN) {
                player.ws.send(message);
            }
        });
    }
}

const server = http.createServer((req, res) => {
    res.writeHead(200, { 'Content-Type': 'text/plain' });
    res.end('WebSocket server is running.\n');
});

const wss = new WebSocketServer({ server });
const gameServer = new GameServer();

wss.on('connection', ws => {
    const player = gameServer.addPlayer(ws);

    ws.on('message', message => {
        gameServer.handleMessage(player.id, message.toString());
    });

    ws.on('close', () => {
        gameServer.removePlayer(player.id);
    });

    ws.on('error', error => {
        console.error(`WebSocket error for player ${player.id}:`, error);
        gameServer.removePlayer(player.id);
    });
});

server.listen(8080, () => {
    console.log('Game server listening on port 8080');
});
```
### ğŸ§ª Senaryo 8: Bir mail sistemi kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k ekler gÃ¶ndermesine izin veriyor. E-postalar ek dosyalarÄ±yla birlikte sunucuda saklanÄ±r. KullanÄ±cÄ±lar Ã§eÅŸitli tÃ¼rde dosyalar ekleyebilir. Mail kutularÄ± zaman iÃ§inde bÃ¼yÃ¼r.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 129
```csharp

using Microsoft.AspNetCore.Mvc;
using System.Collections.Generic;
using System.IO;
using System.Threading.Tasks;
using System;
using Microsoft.AspNetCore.Http;
using System.Linq;

// Simulate a database context for storing mail metadata
public class MailDbContext // In a real app, this would be an actual DB context
{
    private static readonly List<Email> _emails = new List<Email>();
    public List<Email> Emails => _emails;

    public void SaveChanges()
    {
        // Simulate saving to a database
        Console.WriteLine($"Mail data saved. Total emails: {_emails.Count}");
    }
}

public class Email
{
    public Guid Id { get; set; }
    public string Sender { get; set; }
    public string Recipient { get; set; }
    public string Subject { get; set; }
    public string Body { get; set; }
    public DateTime SentDate { get; set; }
    public List<Attachment> Attachments { get; set; } = new List<Attachment>();
    public long TotalSize { get; set; } // Total size of email including attachments
}

public class Attachment
{
    public Guid Id { get; set; }
    public string FileName { get; set; }
    public string StoredPath { get; set; } // Path on server where attachment is stored
    public long Size { get; set; }
    public string ContentType { get; set; }
}

[ApiController]
[Route("[controller]")]
public class MailController : ControllerBase
{
    private readonly MailDbContext _mailDbContext = new MailDbContext(); // Injected in real app
    private readonly string _attachmentStoragePath = Path.Combine(AppDomain.CurrentDomain.BaseDirectory, "MailAttachments");

    public MailController()
    {
        if (!Directory.Exists(_attachmentStoragePath))
        {
            Directory.CreateDirectory(_attachmentStoragePath);
        }
    }

    [HttpPost("send-email")]
    public async Task<IActionResult> SendEmail(
        [FromForm] string sender,
        [FromForm] string recipient,
        [FromForm] string subject,
        [FromForm] string body,
        List<IFormFile> attachments)
    {
        var email = new Email
        {
            Id = Guid.NewGuid(),
            Sender = sender,
            Recipient = recipient,
            Subject = subject,
            Body = body,
            SentDate = DateTime.UtcNow,
            TotalSize = (long)(sender.Length + recipient.Length + subject.Length + body.Length) * sizeof(char) // Estimate base email size
        };

        if (attachments != null && attachments.Any())
        {
            foreach (var attachmentFile in attachments)
            {
                if (attachmentFile.Length == 0) continue;

                var attachmentFileName = $"{Guid.NewGuid()}_{attachmentFile.FileName}";
                var attachmentFilePath = Path.Combine(_attachmentStoragePath, attachmentFileName);

                using (var stream = new FileStream(attachmentFilePath, FileMode.Create))
                {
                    await attachmentFile.CopyToAsync(stream);
                }

                var attachment = new Attachment
                {
                    Id = Guid.NewGuid(),
                    FileName = attachmentFile.FileName,
                    StoredPath = attachmentFilePath,
                    Size = attachmentFile.Length,
                    ContentType = attachmentFile.ContentType
                };
                email.Attachments.Add(attachment);
                email.TotalSize += attachment.Size;
            }
        }

        _mailDbContext.Emails.Add(email);
        _mailDbContext.SaveChanges();

        return Ok(new { Message = "Email sent successfully", EmailId = email.Id, TotalSizeKB = email.TotalSize / 1024.0 });
    }

    [HttpGet("inbox/{recipient}")]
    public IActionResult GetInbox(string recipient)
    {
        var inboxEmails = _mailDbContext.Emails
            .Where(e => e.Recipient == recipient)
            .Select(e => new
            {
                e.Id,
                e.Sender,
                e.Subject,
                e.SentDate,
                AttachmentCount = e.Attachments.Count,
                e.TotalSize
            })
            .ToList();

        return Ok(inboxEmails);
    }
}
```
### ğŸ§ª Senaryo 8: Bir mail sistemi kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k ekler gÃ¶ndermesine izin veriyor. E-postalar ek dosyalarÄ±yla birlikte sunucuda saklanÄ±r. KullanÄ±cÄ±lar Ã§eÅŸitli tÃ¼rde dosyalar ekleyebilir. Mail kutularÄ± zaman iÃ§inde bÃ¼yÃ¼r.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 94
```python

from flask import Flask, request, jsonify, send_from_directory
import os
import uuid
from datetime import datetime

app = Flask(__name__)
ATTACHMENT_FOLDER = 'mail_attachments'
app.config['ATTACHMENT_FOLDER'] = ATTACHMENT_FOLDER

if not os.path.exists(ATTACHMENT_FOLDER):
    os.makedirs(ATTACHMENT_FOLDER)

# In-memory "database" for demonstration
emails_db = []

class Email:
    def __init__(self, sender, recipient, subject, body, attachments_data):
        self.id = str(uuid.uuid4())
        self.sender = sender
        self.recipient = recipient
        self.subject = subject
        self.body = body
        self.sent_date = datetime.utcnow()
        self.attachments = attachments_data # List of Attachment objects
        self.total_size = len(sender) + len(recipient) + len(subject) + len(body) # Basic string size estimate
        for att in attachments_data:
            self.total_size += att['size']

class Attachment:
    def __init__(self, filename, stored_path, size, content_type):
        self.id = str(uuid.uuid4())
        self.filename = filename
        self.stored_path = stored_path
        self.size = size
        self.content_type = content_type

@app.route('/send-email', methods=['POST'])
def send_email():
    sender = request.form.get('sender')
    recipient = request.form.get('recipient')
    subject = request.form.get('subject')
    body = request.form.get('body')
    attachments_files = request.files.getlist('attachments')

    if not all([sender, recipient, subject, body]):
        return jsonify({'error': 'Missing required email fields'}), 400

    attachments_data = []
    for attachment_file in attachments_files:
        if attachment_file.filename == '':
            continue
        
        unique_filename = f"{uuid.uuid4()}_{attachment_file.filename}"
        attachment_filepath = os.path.join(app.config['ATTACHMENT_FOLDER'], unique_filename)
        attachment_file.save(attachment_filepath)
        
        attachments_data.append({
            'filename': attachment_file.filename,
            'stored_path': attachment_filepath,
            'size': os.path.getsize(attachment_filepath),
            'content_type': attachment_file.content_type
        })
    
    email = Email(sender, recipient, subject, body, attachments_data)
    emails_db.append(email)

    return jsonify({
        'message': 'Email sent successfully',
        'email_id': email.id,
        'total_size_kb': email.total_size / 1024.0
    }), 200

@app.route('/inbox/<recipient>', methods=['GET'])
def get_inbox(recipient):
    inbox_emails = []
    for email in emails_db:
        if email.recipient == recipient:
            inbox_emails.append({
                'id': email.id,
                'sender': email.sender,
                'subject': email.subject,
                'sent_date': email.sent_date.isoformat(),
                'attachment_count': len(email.attachments),
                'total_size': email.total_size
            })
    return jsonify(inbox_emails)

@app.route('/attachments/<attachment_filename>', methods=['GET'])
def get_attachment(attachment_filename):
    return send_from_directory(app.config['ATTACHMENT_FOLDER'], attachment_filename)

if __name__ == '__main__':
    app.run(debug=True)
```
### ğŸ§ª Senaryo 8: Bir mail sistemi kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k ekler gÃ¶ndermesine izin veriyor. E-postalar ek dosyalarÄ±yla birlikte sunucuda saklanÄ±r. KullanÄ±cÄ±lar Ã§eÅŸitli tÃ¼rde dosyalar ekleyebilir. Mail kutularÄ± zaman iÃ§inde bÃ¼yÃ¼r.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 122
```typescript

import express from 'express';
import multer from 'multer';
import path from 'path';
import fs from 'fs';
import { v4 as uuidv4 } from 'uuid';

const app = express();
const port = 3000;

const attachmentStoragePath = path.join(__dirname, 'mail_attachments');
if (!fs.existsSync(attachmentStoragePath)) {
    fs.mkdirSync(attachmentStoragePath, { recursive: true });
}

// In-memory "database" for demonstration
interface Attachment {
    id: string;
    fileName: string;
    storedPath: string;
    size: number;
    contentType: string;
}

interface Email {
    id: string;
    sender: string;
    recipient: string;
    subject: string;
    body: string;
    sentDate: Date;
    attachments: Attachment[];
    totalSize: number; // in bytes
}

const emails: Email[] = [];

const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        cb(null, attachmentStoragePath);
    },
    filename: (req, file, cb) => {
        cb(null, `${uuidv4()}_${file.originalname}`);
    }
});

const upload = multer({ storage: storage });

app.post('/send-email', upload.array('attachments'), (req, res) => {
    const { sender, recipient, subject, body } = req.body;
    const files = req.files as Express.Multer.File[];

    if (!sender || !recipient || !subject || !body) {
        return res.status(400).send('Missing required email fields.');
    }

    let totalEmailSize = Buffer.byteLength(sender, 'utf8') + Buffer.byteLength(recipient, 'utf8') +
                          Buffer.byteLength(subject, 'utf8') + Buffer.byteLength(body, 'utf8');

    const attachments: Attachment[] = [];
    if (files && files.length > 0) {
        files.forEach(file => {
            const attachment: Attachment = {
                id: uuidv4(),
                fileName: file.originalname,
                storedPath: file.path,
                size: file.size,
                contentType: file.mimetype
            };
            attachments.push(attachment);
            totalEmailSize += file.size;
        });
    }

    const newEmail: Email = {
        id: uuidv4(),
        sender,
        recipient,
        subject,
        body,
        sentDate: new Date(),
        attachments,
        totalSize: totalEmailSize
    };

    emails.push(newEmail);
    console.log(`Email sent: ${newEmail.id} from ${sender} to ${recipient} with ${attachments.length} attachments. Total size: ${newEmail.totalSize} bytes.`);

    res.status(200).json({
        message: 'Email sent successfully',
        emailId: newEmail.id,
        totalSizeKB: newEmail.totalSize / 1024
    });
});

app.get('/inbox/:recipient', (req, res) => {
    const targetRecipient = req.params.recipient;
    const inboxEmails = emails
        .filter(email => email.recipient === targetRecipient)
        .map(email => ({
            id: email.id,
            sender: email.sender,
            subject: email.subject,
            sentDate: email.sentDate,
            attachmentCount: email.attachments.length,
            totalSize: email.totalSize
        }));
    res.status(200).json(inboxEmails);
});

app.get('/attachments/:filename', (req, res) => {
    const filePath = path.join(attachmentStoragePath, req.params.filename);
    if (fs.existsSync(filePath)) {
        res.sendFile(filePath);
    } else {
        res.status(404).send('Attachment not found.');
    }
});

app.listen(port, () => {
    console.log(`Mail system listening on http://localhost:${port}`);
});
```
### ğŸ§ª Senaryo 9: Bir raporlama sistemi bÃ¼yÃ¼k veri setleri Ã¼zerinde analiz yapÄ±yor. KullanÄ±cÄ±lar geniÅŸ tarih aralÄ±klarÄ±nda raporlar oluÅŸturabilir. Sistem milyonlarca kayÄ±t Ã¼zerinde hesaplama yapar. OluÅŸturulan raporlar kullanÄ±cÄ±lara sunulur.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 155
```csharp

using Microsoft.AspNetCore.Mvc;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;
using System.IO;

// Simulate a data source with millions of records
public class SalesRecord
{
    public Guid Id { get; set; }
    public DateTime SaleDate { get; set; }
    public decimal Amount { get; set; }
    public string Region { get; set; }
    public string ProductType { get; set; }
    public int Quantity { get; set; }
}

public interface IDataRepository
{
    IQueryable<SalesRecord> GetSalesRecords();
}

public class MockDataRepository : IDataRepository
{
    private static List<SalesRecord> _mockRecords = new List<SalesRecord>();
    private static readonly object _lock = new object();

    static MockDataRepository()
    {
        // Simulate a large dataset (e.g., 5 million records)
        if (_mockRecords.Count == 0)
        {
            lock (_lock)
            {
                if (_mockRecords.Count == 0)
                {
                    Console.WriteLine("Generating mock sales data...");
                    var random = new Random();
                    var startDate = DateTime.UtcNow.AddYears(-2);
                    var regions = new[] { "North", "South", "East", "West", "Central" };
                    var productTypes = new[] { "Electronics", "Clothing", "Books", "Home Goods", "Food" };

                    for (int i = 0; i < 5_000_000; i++) // 5 million records
                    {
                        _mockRecords.Add(new SalesRecord
                        {
                            Id = Guid.NewGuid(),
                            SaleDate = startDate.AddDays(random.Next(0, 730)).AddHours(random.Next(0, 24)).AddMinutes(random.Next(0, 60)),
                            Amount = (decimal)(random.NextDouble() * 1000 + 10), // $10 - $1010
                            Region = regions[random.Next(regions.Length)],
                            ProductType = productTypes[random.Next(productTypes.Length)],
                            Quantity = random.Next(1, 10)
                        });
                    }
                    Console.WriteLine($"Generated {_mockRecords.Count} mock sales records.");
                }
            }
        }
    }

    public IQueryable<SalesRecord> GetSalesRecords()
    {
        return _mockRecords.AsQueryable();
    }
}

public class SalesReportCriteria
{
    public DateTime StartDate { get; set; }
    public DateTime EndDate { get; set; }
    public string Region { get; set; }
    public string ProductType { get; set; }
}

public class SalesReport
{
    public DateTime ReportGeneratedDate { get; set; }
    public SalesReportCriteria Criteria { get; set; }
    public long TotalRecordsAnalyzed { get; set; }
    public decimal TotalSalesAmount { get; set; }
    public Dictionary<string, decimal> SalesByRegion { get; set; }
    public Dictionary<string, decimal> SalesByProductType { get; set; }
    public List<DailySalesSummary> DailySalesSummaries { get; set; }
}

public class DailySalesSummary
{
    public DateTime Date { get; set; }
    public decimal TotalSales { get; set; }
    public long NumberOfTransactions { get; set; }
}

[ApiController]
[Route("[controller]")]
public class ReportController : ControllerBase
{
    private readonly IDataRepository _dataRepository;

    public ReportController(IDataRepository dataRepository)
    {
        _dataRepository = dataRepository;
    }

    [HttpGet("generate-sales-report")]
    public async Task<IActionResult> GenerateSalesReport([FromQuery] SalesReportCriteria criteria)
    {
        // Basic validation
        if (criteria.StartDate >= criteria.EndDate)
        {
            return BadRequest("Start date must be before end date.");
        }

        Console.WriteLine($"Generating sales report for {criteria.StartDate} to {criteria.EndDate}");

        // Simulate heavy data processing
        // In a real application, this would involve database queries, aggregations, etc.
        var query = _dataRepository.GetSalesRecords()
            .Where(s => s.SaleDate >= criteria.StartDate && s.SaleDate <= criteria.EndDate);

        if (!string.IsNullOrEmpty(criteria.Region))
        {
            query = query.Where(s => s.Region == criteria.Region);
        }
        if (!string.IsNullOrEmpty(criteria.ProductType))
        {
            query = query.Where(s => s.ProductType == criteria.ProductType);
        }

        var filteredRecords = await Task.Run(() => query.ToList()); // Simulate async data retrieval

        var report = new SalesReport
        {
            ReportGeneratedDate = DateTime.UtcNow,
            Criteria = criteria,
            TotalRecordsAnalyzed = filteredRecords.Count,
            TotalSalesAmount = filteredRecords.Sum(s => s.Amount),
            SalesByRegion = filteredRecords.GroupBy(s => s.Region).ToDictionary(g => g.Key, g => g.Sum(s => s.Amount)),
            SalesByProductType = filteredRecords.GroupBy(s => s.ProductType).ToDictionary(g => g.Key, g => g.Sum(s => s.Amount)),
            DailySalesSummaries = filteredRecords.GroupBy(s => s.SaleDate.Date)
                                                .Select(g => new DailySalesSummary
                                                {
                                                    Date = g.Key,
                                                    TotalSales = g.Sum(s => s.Amount),
                                                    NumberOfTransactions = g.Count()
                                                })
                                                .OrderBy(s => s.Date)
                                                .ToList()
        };

        Console.WriteLine($"Report generated with {report.TotalRecordsAnalyzed} records processed.");
        return Ok(report);
    }
}
```
### ğŸ§ª Senaryo 9: Bir raporlama sistemi bÃ¼yÃ¼k veri setleri Ã¼zerinde analiz yapÄ±yor. KullanÄ±cÄ±lar geniÅŸ tarih aralÄ±klarÄ±nda raporlar oluÅŸturabilir. Sistem milyonlarca kayÄ±t Ã¼zerinde hesaplama yapar. OluÅŸturulan raporlar kullanÄ±cÄ±lara sunulur.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 123
```python

from flask import Flask, request, jsonify
from datetime import datetime, timedelta
import pandas as pd
import random
import uuid
import io

app = Flask(__name__)

# Simulate a large dataset (e.g., 5 million records)
# This would typically come from a database query
_mock_sales_records = []
_data_generated = False

def generate_mock_data(num_records=5_000_000):
    global _mock_sales_records, _data_generated
    if _data_generated:
        return

    print("Generating mock sales data...")
    start_date = datetime.utcnow() - timedelta(days=730) # 2 years back
    regions = ["North", "South", "East", "West", "Central"]
    product_types = ["Electronics", "Clothing", "Books", "Home Goods", "Food"]

    records = []
    for i in range(num_records):
        records.append({
            "id": str(uuid.uuid4()),
            "sale_date": start_date + timedelta(days=random.randint(0, 729), hours=random.randint(0, 23), minutes=random.randint(0, 59)),
            "amount": round(random.uniform(10.0, 1000.0), 2),
            "region": random.choice(regions),
            "product_type": random.choice(product_types),
            "quantity": random.randint(1, 10)
        })
    _mock_sales_records = pd.DataFrame(records)
    _data_generated = True
    print(f"Generated {len(_mock_sales_records)} mock sales records.")

# Ensure data is generated when the app starts
with app.app_context():
    generate_mock_data()

@app.route('/generate-sales-report', methods=['GET'])
def generate_sales_report():
    start_date_str = request.args.get('start_date')
    end_date_str = request.args.get('end_date')
    region = request.args.get('region')
    product_type = request.args.get('product_type')

    if not start_date_str or not end_date_str:
        return jsonify({'error': 'start_date and end_date are required'}), 400

    try:
        start_date = datetime.fromisoformat(start_date_str)
        end_date = datetime.fromisoformat(end_date_str)
    except ValueError:
        return jsonify({'error': 'Invalid date format. Use YYYY-MM-DDTHH:MM:SS format.'}), 400

    if start_date >= end_date:
        return jsonify({'error': 'Start date must be before end date.'}), 400

    print(f"Generating sales report for {start_date} to {end_date}")

    # Filter data based on criteria
    filtered_records = _mock_sales_records[
        (_mock_sales_records['sale_date'] >= start_date) &
        (_mock_sales_records['sale_date'] <= end_date)
    ].copy() # Use .copy() to avoid SettingWithCopyWarning

    if region:
        filtered_records = filtered_records[filtered_records['region'] == region]
    if product_type:
        filtered_records = filtered_records[filtered_records['product_type'] == product_type]

    if filtered_records.empty:
        return jsonify({
            'message': 'No records found for the given criteria.',
            'report_generated_date': datetime.utcnow().isoformat(),
            'criteria': {
                'start_date': start_date_str,
                'end_date': end_date_str,
                'region': region,
                'product_type': product_type
            }
        }), 200

    total_records_analyzed = len(filtered_records)
    total_sales_amount = round(filtered_records['amount'].sum(), 2)

    sales_by_region = filtered_records.groupby('region')['amount'].sum().round(2).to_dict()
    sales_by_product_type = filtered_records.groupby('product_type')['amount'].sum().round(2).to_dict()

    daily_sales_summaries = []
    daily_groups = filtered_records.groupby(filtered_records['sale_date'].dt.date)
    for date, group in daily_groups:
        daily_sales_summaries.append({
            'date': date.isoformat(),
            'total_sales': round(group['amount'].sum(), 2),
            'number_of_transactions': len(group)
        })
    daily_sales_summaries.sort(key=lambda x: x['date']) # Sort by date

    report = {
        'report_generated_date': datetime.utcnow().isoformat(),
        'criteria': {
            'start_date': start_date_str,
            'end_date': end_date_str,
            'region': region,
            'product_type': product_type
        },
        'total_records_analyzed': total_records_analyzed,
        'total_sales_amount': total_sales_amount,
        'sales_by_region': sales_by_region,
        'sales_by_product_type': sales_by_product_type,
        'daily_sales_summaries': daily_sales_summaries
    }

    print(f"Report generated with {total_records_analyzed} records processed.")
    return jsonify(report)

if __name__ == '__main__':
    app.run(debug=True)
```
### ğŸ§ª Senaryo 9: Bir raporlama sistemi bÃ¼yÃ¼k veri setleri Ã¼zerinde analiz yapÄ±yor. KullanÄ±cÄ±lar geniÅŸ tarih aralÄ±klarÄ±nda raporlar oluÅŸturabilir. Sistem milyonlarca kayÄ±t Ã¼zerinde hesaplama yapar. OluÅŸturulan raporlar kullanÄ±cÄ±lara sunulur.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 142
```typescript

import express from 'express';
import { Request, Response } from 'express';

const app = express();
const port = 3000;

interface SalesRecord {
    id: string;
    saleDate: Date;
    amount: number;
    region: string;
    productType: string;
    quantity: number;
}

// Simulate a large dataset (e.g., 5 million records)
const mockSalesRecords: SalesRecord[] = [];

function generateMockData(numRecords: number = 5_000_000) {
    if (mockSalesRecords.length > 0) return; // Only generate once

    console.log("Generating mock sales data...");
    const startDate = new Date();
    startDate.setFullYear(startDate.getFullYear() - 2); // 2 years back

    const regions = ["North", "South", "East", "West", "Central"];
    const productTypes = ["Electronics", "Clothing", "Books", "Home Goods", "Food"];

    for (let i = 0; i < numRecords; i++) {
        const randomDays = Math.floor(Math.random() * 730);
        const randomHours = Math.floor(Math.random() * 24);
        const randomMinutes = Math.floor(Math.random() * 60);

        const saleDate = new Date(startDate);
        saleDate.setDate(saleDate.getDate() + randomDays);
        saleDate.setHours(saleDate.getHours() + randomHours);
        saleDate.setMinutes(saleDate.getMinutes() + randomMinutes);

        mockSalesRecords.push({
            id: Math.random().toString(36).substring(2, 15),
            saleDate: saleDate,
            amount: parseFloat((Math.random() * 1000 + 10).toFixed(2)),
            region: regions[Math.floor(Math.random() * regions.length)],
            productType: productTypes[Math.floor(Math.random() * productTypes.length)],
            quantity: Math.floor(Math.random() * 9) + 1
        });
    }
    console.log(`Generated ${mockSalesRecords.length} mock sales records.`);
}

// Generate data on server startup
generateMockData();

app.get('/generate-sales-report', (req: Request, res: Response) => {
    const { startDate, endDate, region, productType } = req.query;

    if (!startDate || !endDate) {
        return res.status(400).send('startDate and endDate are required.');
    }

    const startDateTime = new Date(startDate as string);
    const endDateTime = new Date(endDate as string);

    if (isNaN(startDateTime.getTime()) || isNaN(endDateTime.getTime())) {
        return res.status(400).send('Invalid date format. Use ISO 8601 format (YYYY-MM-DDTHH:MM:SSZ).');
    }

    if (startDateTime >= endDateTime) {
        return res.status(400).send('Start date must be before end date.');
    }

    console.log(`Generating sales report for ${startDateTime.toISOString()} to ${endDateTime.toISOString()}`);

    // Filter records
    let filteredRecords = mockSalesRecords.filter(record =>
        record.saleDate >= startDateTime && record.saleDate <= endDateTime
    );

    if (region) {
        filteredRecords = filteredRecords.filter(record => record.region === region);
    }
    if (productType) {
        filteredRecords = filteredRecords.filter(record => record.productType === productType);
    }

    if (filteredRecords.length === 0) {
        return res.status(200).json({
            message: 'No records found for the given criteria.',
            reportGeneratedDate: new Date().toISOString(),
            criteria: { startDate, endDate, region, productType }
        });
    }

    const totalRecordsAnalyzed = filteredRecords.length;
    const totalSalesAmount = parseFloat(filteredRecords.reduce((sum, record) => sum + record.amount, 0).toFixed(2));

    const salesByRegion = filteredRecords.reduce((acc, record) => {
        acc[record.region] = (acc[record.region] || 0) + record.amount;
        return acc;
    }, {} as { [key: string]: number });

    const salesByProductType = filteredRecords.reduce((acc, record) => {
        acc[record.productType] = (acc[record.productType] || 0) + record.amount;
        return acc;
    }, {} as { [key: string]: number });

    const dailySalesSummariesMap: { [date: string]: { totalSales: number; numberOfTransactions: number } } = {};
    filteredRecords.forEach(record => {
        const dateKey = record.saleDate.toISOString().split('T')[0]; // YYYY-MM-DD
        if (!dailySalesSummariesMap[dateKey]) {
            dailySalesSummariesMap[dateKey] = { totalSales: 0, numberOfTransactions: 0 };
        }
        dailySalesSummariesMap[dateKey].totalSales += record.amount;
        dailySalesSummariesMap[dateKey].numberOfTransactions++;
    });

    const dailySalesSummaries = Object.keys(dailySalesSummariesMap)
        .map(date => ({
            date: date,
            totalSales: parseFloat(dailySalesSummariesMap[date].totalSales.toFixed(2)),
            numberOfTransactions: dailySalesSummariesMap[date].numberOfTransactions
        }))
        .sort((a, b) => new Date(a.date).getTime() - new Date(b.date).getTime());

    const report = {
        reportGeneratedDate: new Date().toISOString(),
        criteria: { startDate, endDate, region, productType },
        totalRecordsAnalyzed,
        totalSalesAmount,
        salesByRegion,
        salesByProductType,
        dailySalesSummaries
    };

    console.log(`Report generated with ${totalRecordsAnalyzed} records processed.`);
    res.status(200).json(report);
});

app.listen(port, () => {
    console.log(`Reporting system listening on http://localhost:${port}`);
});
```
### ğŸ§ª Senaryo 10: Bir backup sistemi kullanÄ±cÄ± verilerini dÃ¼zenli olarak yedekliyor. FarklÄ± boyutlardaki dosyalar yedekleme sÃ¼recine dahil edilir. Sistem tÃ¼m kullanÄ±cÄ± verilerini r ve arÅŸivler. Yedekleme iÅŸlemi otomatik olarak Ã§alÄ±ÅŸÄ±r.
**ğŸ’» Dil:** `C#`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 128
```csharp

using System;
using System.IO;
using System.IO.Compression;
using System.Threading.Tasks;
using System.Collections.Generic;
using System.Linq;

public class BackupService
{
    private readonly string _sourceDirectory;
    private readonly string _backupDirectory;

    public BackupService(string sourceDirectory, string backupDirectory)
    {
        _sourceDirectory = sourceDirectory;
        _backupDirectory = backupDirectory;

        if (!Directory.Exists(_backupDirectory))
        {
            Directory.CreateDirectory(_backupDirectory);
        }
    }

    public async Task<BackupResult> PerformBackupAsync()
    {
        Console.WriteLine($"Starting backup from '{_sourceDirectory}' to '{_backupDirectory}'...");
        var startTime = DateTime.UtcNow;
        long totalFilesBackedUp = 0;
        long totalBytesBackedUp = 0;

        try
        {
            // Create a timestamped backup folder or zip file
            var backupFileName = $"backup_{DateTime.Now:yyyyMMdd_HHmmss}.zip";
            var backupFilePath = Path.Combine(_backupDirectory, backupFileName);

            using (var zipArchiveStream = new FileStream(backupFilePath, FileMode.Create))
            using (var archive = new ZipArchive(zipArchiveStream, ZipArchiveMode.Create))
            {
                var allFiles = Directory.GetFiles(_sourceDirectory, "*", SearchOption.AllDirectories);
                foreach (var filePath in allFiles)
                {
                    var relativePath = Path.GetRelativePath(_sourceDirectory, filePath);
                    var entry = archive.CreateEntry(relativePath);

                    using (var entryStream = entry.Open())
                    using (var fileStream = new FileStream(filePath, FileMode.Open, FileAccess.Read))
                    {
                        await fileStream.CopyToAsync(entryStream);
                    }

                    totalFilesBackedUp++;
                    totalBytesBackedUp += new FileInfo(filePath).Length;
                    Console.WriteLine($"Backed up: {relativePath} ({new FileInfo(filePath).Length} bytes)");
                }
            }

            var endTime = DateTime.UtcNow;
            var duration = endTime - startTime;
            Console.WriteLine($"Backup completed successfully in {duration.TotalSeconds:F2} seconds.");

            return new BackupResult
            {
                Success = true,
                BackupPath = backupFilePath,
                FilesBackedUp = totalFilesBackedUp,
                BytesBackedUp = totalBytesBackedUp,
                Duration = duration,
                ErrorMessage = null
            };
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Backup failed: {ex.Message}");
            return new BackupResult
            {
                Success = false,
                BackupPath = null,
                FilesBackedUp = totalFilesBackedUp,
                BytesBackedUp = totalBytesBackedUp,
                Duration = DateTime.UtcNow - startTime,
                ErrorMessage = ex.Message
            };
        }
    }
}

public class BackupResult
{
    public bool Success { get; set; }
    public string BackupPath { get; set; }
    public long FilesBackedUp { get; set; }
    public long BytesBackedUp { get; set; }
    public TimeSpan Duration { get; set; }
    public string ErrorMessage { get; set; }
}

// Example usage:
/*
public class Program
{
    public static async Task Main(string[] args)
    {
        // Create some dummy data to back up
        string sourceDir = Path.Combine(AppDomain.CurrentDomain.BaseDirectory, "UserData");
        string backupDir = Path.Combine(AppDomain.CurrentDomain.BaseDirectory, "Backups");

        if (!Directory.Exists(sourceDir)) Directory.CreateDirectory(sourceDir);
        File.WriteAllText(Path.Combine(sourceDir, "document1.txt"), "This is some important data.");
        File.WriteAllBytes(Path.Combine(sourceDir, "image.bin"), new byte[1024 * 1024 * 5]); // 5 MB dummy file

        var backupService = new BackupService(sourceDir, backupDir);
        var result = await backupService.PerformBackupAsync();

        Console.WriteLine($"Backup Status: {(result.Success ? "SUCCESS" : "FAILED")}");
        if (result.Success)
        {
            Console.WriteLine($"Backup created at: {result.BackupPath}");
            Console.WriteLine($"Total files: {result.FilesBackedUp}, Total bytes: {result.BytesBackedUp}");
        }
        else
        {
            Console.WriteLine($"Error: {result.ErrorMessage}");
        }
    }
}
*/
```
### ğŸ§ª Senaryo 10: Bir backup sistemi kullanÄ±cÄ± verilerini dÃ¼zenli olarak yedekliyor. FarklÄ± boyutlardaki dosyalar yedekleme sÃ¼recine dahil edilir. Sistem tÃ¼m kullanÄ±cÄ± verilerini r ve arÅŸivler. Yedekleme iÅŸlemi otomatik olarak Ã§alÄ±ÅŸÄ±r.
**ğŸ’» Dil:** `Python`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 85
```python

import os
import shutil
import datetime
import zipfile

class BackupService:
    def __init__(self, source_directory, backup_directory):
        self.source_directory = source_directory
        self.backup_directory = backup_directory

        if not os.path.exists(self.backup_directory):
            os.makedirs(self.backup_directory)

    def perform_backup(self):
        print(f"Starting backup from '{self.source_directory}' to '{self.backup_directory}'...")
        start_time = datetime.datetime.utcnow()
        total_files_backed_up = 0
        total_bytes_backed_up = 0
        backup_path = None
        error_message = None
        success = False

        try:
            # Create a timestamped zip file for the backup
            backup_filename = f"backup_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
            backup_path = os.path.join(self.backup_directory, backup_filename)

            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(self.source_directory):
                    for file in files:
                        file_path = os.path.join(root, file)
                        # arcname is the name of the file inside the zip archive
                        arcname = os.path.relpath(file_path, self.source_directory)
                        
                        zipf.write(file_path, arcname)
                        
                        file_size = os.path.getsize(file_path)
                        total_files_backed_up += 1
                        total_bytes_backed_up += file_size
                        print(f"Backed up: {arcname} ({file_size} bytes)")
            
            end_time = datetime.datetime.utcnow()
            duration = end_time - start_time
            success = True
            print(f"Backup completed successfully in {duration.total_seconds():.2f} seconds.")

        except Exception as e:
            error_message = str(e)
            print(f"Backup failed: {error_message}")
        finally:
            end_time = datetime.datetime.utcnow()
            duration = end_time - start_time

        return {
            'success': success,
            'backup_path': backup_path,
            'files_backed_up': total_files_backed_up,
            'bytes_backed_up': total_bytes_backed_up,
            'duration_seconds': duration.total_seconds(),
            'error_message': error_message
        }

# Example usage:
# if __name__ == '__main__':
#     # Create some dummy data to back up
#     source_dir = os.path.join(os.getcwd(), "UserData")
#     backup_dir = os.path.join(os.getcwd(), "Backups")

#     if not os.path.exists(source_dir):
#         os.makedirs(source_dir)
#     with open(os.path.join(source_dir, "document1.txt"), "w") as f:
#         f.write("This is some important data.")
#     with open(os.path.join(source_dir, "large_file.bin"), "wb") as f:
#         f.write(os.urandom(5 * 1024 * 1024)) # 5 MB dummy file

#     backup_service = BackupService(source_dir, backup_dir)
#     result = backup_service.perform_backup()

#     print(f"Backup Status: {'SUCCESS' if result['success'] else 'FAILED'}")
#     if result['success']:
#         print(f"Backup created at: {result['backup_path']}")
#         print(f"Total files: {result['files_backed_up']}, Total bytes: {result['bytes_backed_up']}")
#     else:
#         print(f"Error: {result['error_message']}")
```
### ğŸ§ª Senaryo 10: Bir backup sistemi kullanÄ±cÄ± verilerini dÃ¼zenli olarak yedekliyor. FarklÄ± boyutlardaki dosyalar yedekleme sÃ¼recine dahil edilir. Sistem tÃ¼m kullanÄ±cÄ± verilerini r ve arÅŸivler. Yedekleme iÅŸlemi otomatik olarak Ã§alÄ±ÅŸÄ±r.
**ğŸ’» Dil:** `TypeScript (Node.js)`

**ğŸ¤– AI:** Gemini

**SatÄ±r SayÄ±sÄ±:** 139
```typescript

import * as fs from 'fs';
import * as path from 'path';
import archiver from 'archiver'; // For creating zip archives
import { setTimeout } from 'timers/promises';

interface BackupResult {
    success: boolean;
    backupPath: string | null;
    filesBackedUp: number;
    bytesBackedUp: number;
    durationSeconds: number;
    errorMessage: string | null;
}

export class BackupService {
    private sourceDirectory: string;
    private backupDirectory: string;

    constructor(sourceDirectory: string, backupDirectory: string) {
        this.sourceDirectory = sourceDirectory;
        this.backupDirectory = backupDirectory;

        if (!fs.existsSync(this.backupDirectory)) {
            fs.mkdirSync(this.backupDirectory, { recursive: true });
        }
    }

    public async performBackup(): Promise<BackupResult> {
        console.log(`Starting backup from '${this.sourceDirectory}' to '${this.backupDirectory}'...`);
        const startTime = process.hrtime.bigint(); // High-resolution time

        let totalFilesBackedUp = 0;
        let totalBytesBackedUp = 0;
        let backupPath: string | null = null;
        let errorMessage: string | null = null;
        let success = false;

        try {
            const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
            const backupFileName = `backup_${timestamp}.zip`;
            backupPath = path.join(this.backupDirectory, backupFileName);

            const output = fs.createWriteStream(backupPath);
            const archive = archiver('zip', {
                zlib: { level: 9 } // Sets the compression level.
            });

            archive.on('warning', function(err) {
                if (err.code === 'ENOENT') {
                    console.warn('Archiver warning:', err.message);
                } else {
                    throw err;
                }
            });

            archive.on('error', function(err) {
                throw err;
            });

            archive.pipe(output);

            const files = await this.getAllFiles(this.sourceDirectory);

            for (const filePath of files) {
                const relativePath = path.relative(this.sourceDirectory, filePath);
                const stats = fs.statSync(filePath); // Get file stats to get size
                totalBytesBackedUp += stats.size;
                archive.file(filePath, { name: relativePath });
                totalFilesBackedUp++;
                // console.log(`Backed up: ${relativePath} (${stats.size} bytes)`);
            }

            await archive.finalize(); // Finalize the archive (closes the stream)

            success = true;
            console.log(`Backup completed successfully to ${backupPath}.`);

        } catch (error: any) {
            errorMessage = error.message;
            console.error(`Backup failed: ${errorMessage}`);
            // Clean up incomplete backup file if it exists
            if (backupPath && fs.existsSync(backupPath)) {
                fs.unlinkSync(backupPath);
            }
        } finally {
            const endTime = process.hrtime.bigint();
            const durationSeconds = Number(endTime - startTime) / 1_000_000_000;

            return {
                success,
                backupPath,
                filesBackedUp: totalFilesBackedUp,
                bytesBackedUp: totalBytesBackedUp,
                durationSeconds: parseFloat(durationSeconds.toFixed(2)),
                errorMessage
            };
        }
    }

    private async getAllFiles(dir: string): Promise<string[]> {
        let files: string[] = [];
        const items = await fs.promises.readdir(dir, { withFileTypes: true });

        for (const item of items) {
            const fullPath = path.join(dir, item.name);
            if (item.isDirectory()) {
                files = files.concat(await this.getAllFiles(fullPath));
            } else {
                files.push(fullPath);
            }
        }
        return files;
    }
}

// Example usage:
// (async () => {
//     // Create some dummy data to back up
//     const sourceDir = path.join(__dirname, "UserData");
//     const backupDir = path.join(__dirname, "Backups");

//     if (!fs.existsSync(sourceDir)) {
//         fs.mkdirSync(sourceDir);
//     }
//     fs.writeFileSync(path.join(sourceDir, "document1.txt"), "This is some important data.");
//     fs.writeFileSync(path.join(sourceDir, "image.bin"), Buffer.alloc(5 * 1024 * 1024)); // 5 MB dummy file

//     const backupService = new BackupService(sourceDir, backupDir);
//     const result = await backupService.performBackup();

//     console.log(`\nBackup Status: ${result.success ? "SUCCESS" : "FAILED"}`);
//     if (result.success) {
//         console.log(`Backup created at: ${result.backupPath}`);
//         console.log(`Total files: ${result.filesBackedUp}, Total bytes: ${result.bytesBackedUp}`);
//         console.log(`Duration: ${result.durationSeconds} seconds`);
//     } else {
//         console.log(`Error: ${result.errorMessage}`);
//     }
```
// })();